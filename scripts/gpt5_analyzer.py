"""
GPT-5 Prompt Analyzer
GPT-5 íŠ¹í™” í”„ë¡¬í”„íŠ¸ ë¶„ì„ê¸°

GPT-5 prompting guide ê¸°ë°˜ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤:
- ëª¨ìˆœ íƒì§€
- Agentic êµ¬ì¡° í‰ê°€
- íŒŒë¼ë¯¸í„° ì¶”ì²œ (reasoning_effort, verbosity)
- ë„êµ¬ í”„ë¦¬ì•°ë¸” í’ˆì§ˆ
- XML êµ¬ì¡° ê²€ì‚¬
"""

import re
import json
from dataclasses import dataclass, asdict
from enum import Enum
from typing import List, Dict, Tuple, Optional
from pathlib import Path


class ReasoningEffort(Enum):
    """Reasoning effort ë ˆë²¨"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"


class Verbosity(Enum):
    """Verbosity ë ˆë²¨"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"


class Severity(Enum):
    """ì´ìŠˆ ì‹¬ê°ë„"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


@dataclass
class Contradiction:
    """ëª¨ìˆœ ì •ë³´"""
    pattern: str
    description: str
    example: str
    severity: str
    location: str
    fix_strategy: str


@dataclass
class GPT5AnalysisResult:
    """GPT-5 ë¶„ì„ ê²°ê³¼"""
    original_prompt: str
    contradictions: List[Contradiction]
    agentic_score: float  # 0-10
    clarity_score: float  # 0-10
    context_efficiency_score: float  # 0-10
    tool_preamble_quality: float  # 0-10
    reasoning_effort_recommendation: str
    verbosity_recommendation: str
    xml_structured: bool
    issues: List[Dict[str, str]]
    suggestions: List[str]
    complexity_score: float  # 0-10

    def to_dict(self) -> Dict:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        result = asdict(self)
        # Contradiction ê°ì²´ë“¤ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        result['contradictions'] = [asdict(c) for c in self.contradictions]
        return result


class GPT5PromptAnalyzer:
    """GPT-5 ì „ìš© í”„ë¡¬í”„íŠ¸ ë¶„ì„ê¸°"""

    def __init__(self, patterns_file: Optional[str] = None):
        """
        ì´ˆê¸°í™”

        Args:
            patterns_file: GPT-5 íŒ¨í„´ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©)
        """
        if patterns_file is None:
            # ê¸°ë³¸ íŒ¨í„´ íŒŒì¼ ê²½ë¡œ
            current_dir = Path(__file__).parent
            patterns_file = current_dir.parent / "references" / "patterns" / "gpt5_patterns.json"

        with open(patterns_file, 'r', encoding='utf-8') as f:
            self.patterns = json.load(f)

    def detect_contradictions(self, prompt: str) -> List[Contradiction]:
        """
        ëª¨ìˆœë˜ëŠ” ì§€ì‹œì‚¬í•­ íƒì§€

        Args:
            prompt: ë¶„ì„í•  í”„ë¡¬í”„íŠ¸

        Returns:
            ê°ì§€ëœ ëª¨ìˆœ ë¦¬ìŠ¤íŠ¸
        """
        contradictions = []
        prompt_lower = prompt.lower()

        for pattern_info in self.patterns['contradiction_patterns']['common_contradictions']:
            patterns = pattern_info['pattern']

            # ë‘ íŒ¨í„´ì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            matches = []
            for p in patterns:
                match = re.search(p, prompt_lower, re.IGNORECASE)
                if match:
                    matches.append((match.group(), match.start()))

            # ë‘ íŒ¨í„´ì´ ëª¨ë‘ ë°œê²¬ë˜ë©´ ëª¨ìˆœ
            if len(matches) >= 2:
                location = f"ìœ„ì¹˜: {matches[0][1]}, {matches[1][1]}"
                contradictions.append(Contradiction(
                    pattern=" vs ".join(patterns),
                    description=pattern_info['description'],
                    example=pattern_info['example'],
                    severity=pattern_info['severity'],
                    location=location,
                    fix_strategy=pattern_info['fix_strategy']
                ))

        # ì ˆëŒ€ ê¸ˆì§€ + ì ˆëŒ€ í•„ìˆ˜ í‚¤ì›Œë“œ ì¡°í•© ê²€ì‚¬
        prohibitions = self.patterns['contradiction_patterns']['detection_keywords']['absolute_prohibitions']
        requirements = self.patterns['contradiction_patterns']['detection_keywords']['absolute_requirements']

        for prohibition in prohibitions:
            for requirement in requirements:
                if prohibition in prompt_lower and requirement in prompt_lower:
                    # ê°™ì€ ë¬¸ë§¥ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸ (50ì ì´ë‚´)
                    prohibition_pos = prompt_lower.find(prohibition)
                    requirement_pos = prompt_lower.find(requirement)

                    if abs(prohibition_pos - requirement_pos) < 100:
                        contradictions.append(Contradiction(
                            pattern=f"{prohibition} vs {requirement}",
                            description="ì ˆëŒ€ ê¸ˆì§€ì™€ ì ˆëŒ€ í•„ìˆ˜ì˜ ëª¨ìˆœ",
                            example=f"ë¬¸ë§¥ì— '{prohibition}'ì™€ '{requirement}'ê°€ í•¨ê»˜ ë‚˜íƒ€ë‚¨",
                            severity="high",
                            location=f"ìœ„ì¹˜: {min(prohibition_pos, requirement_pos)}",
                            fix_strategy="ëª…í™•í•œ ìš°ì„ ìˆœìœ„ ì„¤ì • ë˜ëŠ” ì¡°ê±´ë¶€ ë¡œì§ ì¶”ê°€"
                        ))

        return contradictions

    def analyze_agentic_structure(self, prompt: str) -> Tuple[float, List[str]]:
        """
        Agentic êµ¬ì¡° í‰ê°€

        Args:
            prompt: ë¶„ì„í•  í”„ë¡¬í”„íŠ¸

        Returns:
            (agentic_score, suggestions): ì ìˆ˜(0-10)ì™€ ê°œì„  ì œì•ˆ
        """
        score = 5.0  # ê¸°ë³¸ ì ìˆ˜
        suggestions = []

        # 1. ë„êµ¬ ì‚¬ìš© ëª…ì‹œ ì—¬ë¶€ (+2ì )
        tool_keywords = ['tool', 'function', 'api', 'call', 'ë„êµ¬', 'í•¨ìˆ˜']
        if any(keyword in prompt.lower() for keyword in tool_keywords):
            score += 2
        else:
            suggestions.append("ë„êµ¬ ì‚¬ìš© ë°©ë²•ì„ ëª…ì‹œí•˜ë©´ Agentic êµ¬ì¡°ê°€ ê°œì„ ë©ë‹ˆë‹¤")

        # 2. ì§€ì†ì„± ì§€ì‹œ ì—¬ë¶€ (+2ì )
        persistence_keywords = ['continue', 'keep going', 'until', 'completely', 'ê³„ì†', 'ëê¹Œì§€']
        if any(keyword in prompt.lower() for keyword in persistence_keywords):
            score += 2
        else:
            suggestions.append("ì‘ì—… ì§€ì†ì„± ì§€ì‹œë¥¼ ì¶”ê°€í•˜ë©´ ììœ¨ì„±ì´ í–¥ìƒë©ë‹ˆë‹¤")

        # 3. Escape hatch ì¡´ì¬ ì—¬ë¶€ (+1ì )
        escape_keywords = ['if uncertain', 'if unsure', 'best judgment', 'ë¶ˆí™•ì‹¤í•˜ë©´', 'íŒë‹¨']
        if any(keyword in prompt.lower() for keyword in escape_keywords):
            score += 1
        else:
            suggestions.append("ë¶ˆí™•ì‹¤ì„± ì²˜ë¦¬ ë°©ë²•(escape hatch)ì„ ì¶”ê°€í•˜ì„¸ìš”")

        # 4. ê³¼ë„í•œ ì² ì €í•¨ ê°•ì¡° (-2ì )
        over_thorough = ['maximize', 'all possible', 'every single', 'ëª¨ë“ ', 'ì™„ë²½í•˜ê²Œ']
        if sum(1 for keyword in over_thorough if keyword in prompt.lower()) >= 3:
            score -= 2
            suggestions.append("ê³¼ë„í•œ ì² ì €í•¨ ê°•ì¡°ëŠ” ë¶ˆí•„ìš”í•œ ë„êµ¬ ê³¼ë‹¤ ì‚¬ìš©ì„ ìœ ë°œí•©ë‹ˆë‹¤")

        return max(0, min(10, score)), suggestions

    def analyze_clarity(self, prompt: str) -> Tuple[float, List[str]]:
        """
        ëª…ë ¹ ëª…í™•ì„± í‰ê°€

        Args:
            prompt: ë¶„ì„í•  í”„ë¡¬í”„íŠ¸

        Returns:
            (clarity_score, suggestions): ì ìˆ˜(0-10)ì™€ ê°œì„  ì œì•ˆ
        """
        score = 5.0
        suggestions = []

        # 1. XML êµ¬ì¡° ì‚¬ìš© (+3ì )
        if '<' in prompt and '>' in prompt:
            xml_tags = re.findall(r'<(\w+)>', prompt)
            if len(xml_tags) >= 2:
                score += 3
            else:
                score += 1.5
                suggestions.append("ë” ì²´ê³„ì ì¸ XML êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”")
        else:
            suggestions.append("XML êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ë©´ ëª…í™•ì„±ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤")

        # 2. êµ¬ì¡°í™”ëœ ì„¹ì…˜ (+2ì )
        section_indicators = ['##', '1.', '2.', 'Step', 'ë‹¨ê³„']
        if sum(1 for ind in section_indicators if ind in prompt) >= 2:
            score += 2
        else:
            suggestions.append("ë²ˆí˜¸ë‚˜ ì œëª©ìœ¼ë¡œ ì„¹ì…˜ì„ êµ¬ë¶„í•˜ì„¸ìš”")

        # 3. ì• ë§¤í•œ í‘œí˜„ (-1ì )
        ambiguous = ['as needed', 'when appropriate', 'if necessary', 'í•„ìš”í•˜ë©´', 'ì ì ˆíˆ']
        ambiguous_count = sum(1 for word in ambiguous if word in prompt.lower())
        if ambiguous_count > 2:
            score -= ambiguous_count * 0.5
            suggestions.append(f"ì• ë§¤í•œ í‘œí˜„({ambiguous_count}ê°œ)ì„ êµ¬ì²´ì ìœ¼ë¡œ ë°”ê¾¸ì„¸ìš”")

        return max(0, min(10, score)), suggestions

    def analyze_context_efficiency(self, prompt: str) -> Tuple[float, List[str]]:
        """
        ì»¨í…ìŠ¤íŠ¸ íš¨ìœ¨ì„± í‰ê°€

        Args:
            prompt: ë¶„ì„í•  í”„ë¡¬í”„íŠ¸

        Returns:
            (efficiency_score, suggestions): ì ìˆ˜(0-10)ì™€ ê°œì„  ì œì•ˆ
        """
        score = 7.0  # ê¸°ë³¸ ì ìˆ˜
        suggestions = []

        # ê³¼ë„í•œ ì •ë³´ ìˆ˜ì§‘ ì§€ì‹œ (-3ì )
        excessive = ['maximize context', 'all possible information', 'gather everything',
                     'read all files', 'ëª¨ë“  ì •ë³´', 'ëª¨ë“  íŒŒì¼']
        excessive_count = sum(1 for phrase in excessive if phrase in prompt.lower())
        if excessive_count > 0:
            score -= excessive_count * 1.5
            suggestions.append("ê³¼ë„í•œ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ì§€ì‹œëŠ” í† í°ì„ ë‚­ë¹„í•©ë‹ˆë‹¤")

        # ê· í˜•ì¡íŒ ì ‘ê·¼ (+2ì )
        balanced = ['sufficient', 'relevant', 'necessary', 'í•„ìš”í•œ', 'ê´€ë ¨ëœ']
        if any(word in prompt.lower() for word in balanced):
            score += 2
        else:
            suggestions.append("'sufficient' ë˜ëŠ” 'relevant' ê°™ì€ ê· í˜•ì¡íŒ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”")

        return max(0, min(10, score)), suggestions

    def analyze_tool_preamble(self, prompt: str) -> Tuple[float, List[str]]:
        """
        ë„êµ¬ í”„ë¦¬ì•°ë¸” í’ˆì§ˆ í‰ê°€

        Args:
            prompt: ë¶„ì„í•  í”„ë¡¬í”„íŠ¸

        Returns:
            (quality_score, suggestions): ì ìˆ˜(0-10)ì™€ ê°œì„  ì œì•ˆ
        """
        score = 3.0  # ê¸°ë³¸ ì ìˆ˜ (í”„ë¦¬ì•°ë¸” ì—†ìœ¼ë©´ ë‚®ìŒ)
        suggestions = []

        # ëª©í‘œ ì¬êµ¬ì„± ìš”ì²­ (+2ì )
        restate_keywords = ['rephrase', 'restate', 'clarify goal', 'ì¬êµ¬ì„±', 'ëª…í™•íˆ']
        if any(keyword in prompt.lower() for keyword in restate_keywords):
            score += 2
        else:
            suggestions.append("ì‚¬ìš©ì ëª©í‘œë¥¼ ì¬êµ¬ì„±í•˜ë„ë¡ ìš”ì²­í•˜ì„¸ìš”")

        # ê³„íš ì‘ì„± ìš”ì²­ (+2ì )
        plan_keywords = ['plan', 'outline', 'steps', 'ê³„íš', 'ë‹¨ê³„']
        if any(keyword in prompt.lower() for keyword in plan_keywords):
            score += 2
        else:
            suggestions.append("êµ¬ì¡°í™”ëœ ê³„íšì„ ì‘ì„±í•˜ë„ë¡ ìš”ì²­í•˜ì„¸ìš”")

        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ìš”ì²­ (+3ì )
        progress_keywords = ['progress', 'update', 'status', 'ì§„í–‰', 'ìƒí™©']
        if any(keyword in prompt.lower() for keyword in progress_keywords):
            score += 3
        else:
            suggestions.append("ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ë¥¼ ìš”ì²­í•˜ì„¸ìš”")

        return max(0, min(10, score)), suggestions

    def calculate_complexity(self, prompt: str) -> float:
        """
        í”„ë¡¬í”„íŠ¸ ë³µì¡ë„ ê³„ì‚°

        Args:
            prompt: ë¶„ì„í•  í”„ë¡¬í”„íŠ¸

        Returns:
            ë³µì¡ë„ ì ìˆ˜ (0-10)
        """
        score = 0.0

        # 1. ê¸¸ì´ ê¸°ë°˜ (0-2ì )
        length = len(prompt)
        if length < 100:
            score += 0.5
        elif length < 300:
            score += 1.0
        elif length < 600:
            score += 1.5
        else:
            score += 2.0

        # 2. ë‹¨ê³„ ìˆ˜ (0-2ì )
        steps = len(re.findall(r'(?:step|ë‹¨ê³„)\s*\d+|^\d+\.|^-\s', prompt, re.IGNORECASE | re.MULTILINE))
        score += min(2.0, steps * 0.4)

        # 3. ë„êµ¬ ì‚¬ìš© (0-2ì )
        tool_mentions = len(re.findall(r'(?:tool|function|api|ë„êµ¬|í•¨ìˆ˜)', prompt, re.IGNORECASE))
        score += min(2.0, tool_mentions * 0.5)

        # 4. ì¡°ê±´ë¶€ ë¡œì§ (0-2ì )
        conditionals = len(re.findall(r'(?:if|when|unless|ë§Œì•½|ê²½ìš°)', prompt, re.IGNORECASE))
        score += min(2.0, conditionals * 0.4)

        # 5. ì œì•½ì‚¬í•­ (0-2ì )
        constraints = len(re.findall(r'(?:must|should|constraint|ì œì•½|í•„ìˆ˜)', prompt, re.IGNORECASE))
        score += min(2.0, constraints * 0.4)

        return min(10.0, score)

    def recommend_reasoning_effort(self, complexity: float) -> ReasoningEffort:
        """
        ë³µì¡ë„ ê¸°ë°˜ reasoning effort ì¶”ì²œ

        Args:
            complexity: ë³µì¡ë„ ì ìˆ˜ (0-10)

        Returns:
            ì¶”ì²œ reasoning effort
        """
        thresholds = self.patterns['reasoning_effort_mapping']['complexity_thresholds']

        if complexity <= 3:
            return ReasoningEffort.LOW
        elif complexity <= 7:
            return ReasoningEffort.MEDIUM
        else:
            return ReasoningEffort.HIGH

    def recommend_verbosity(self, prompt: str, complexity: float) -> Verbosity:
        """
        í”„ë¡¬í”„íŠ¸ íŠ¹ì„± ê¸°ë°˜ verbosity ì¶”ì²œ

        Args:
            prompt: ë¶„ì„í•  í”„ë¡¬í”„íŠ¸
            complexity: ë³µì¡ë„ ì ìˆ˜

        Returns:
            ì¶”ì²œ verbosity
        """
        # ê°„ê²°í•¨ ìš”ì²­ í‚¤ì›Œë“œ
        concise_keywords = ['brief', 'concise', 'short', 'quick', 'ê°„ë‹¨íˆ', 'ê°„ê²°í•˜ê²Œ']
        if any(keyword in prompt.lower() for keyword in concise_keywords):
            return Verbosity.LOW

        # ìƒì„¸í•¨ ìš”ì²­ í‚¤ì›Œë“œ
        detailed_keywords = ['detailed', 'comprehensive', 'thorough', 'explain', 'ìƒì„¸íˆ', 'ìì„¸íˆ']
        if any(keyword in prompt.lower() for keyword in detailed_keywords):
            return Verbosity.HIGH

        # ë³µì¡ë„ ê¸°ë°˜
        if complexity < 4:
            return Verbosity.LOW
        elif complexity < 7:
            return Verbosity.MEDIUM
        else:
            return Verbosity.HIGH

    def is_xml_structured(self, prompt: str) -> bool:
        """
        XML êµ¬ì¡° ì‚¬ìš© ì—¬ë¶€ í™•ì¸

        Args:
            prompt: ë¶„ì„í•  í”„ë¡¬í”„íŠ¸

        Returns:
            XML êµ¬ì¡° ì‚¬ìš© ì—¬ë¶€
        """
        # ìµœì†Œ 2ê°œ ì´ìƒì˜ XML íƒœê·¸ ìŒì´ ìˆì–´ì•¼ í•¨
        opening_tags = re.findall(r'<(\w+)>', prompt)
        closing_tags = re.findall(r'</(\w+)>', prompt)

        return len(opening_tags) >= 2 and len(closing_tags) >= 2

    def analyze(self, prompt: str) -> GPT5AnalysisResult:
        """
        ì „ì²´ ë¶„ì„ ìˆ˜í–‰

        Args:
            prompt: ë¶„ì„í•  í”„ë¡¬í”„íŠ¸

        Returns:
            GPT-5 ë¶„ì„ ê²°ê³¼
        """
        # 1. ëª¨ìˆœ íƒì§€
        contradictions = self.detect_contradictions(prompt)

        # 2. ê° ì˜ì—­ ë¶„ì„
        agentic_score, agentic_suggestions = self.analyze_agentic_structure(prompt)
        clarity_score, clarity_suggestions = self.analyze_clarity(prompt)
        context_score, context_suggestions = self.analyze_context_efficiency(prompt)
        tool_preamble_score, tool_suggestions = self.analyze_tool_preamble(prompt)

        # 3. ë³µì¡ë„ ê³„ì‚°
        complexity = self.calculate_complexity(prompt)

        # 4. íŒŒë¼ë¯¸í„° ì¶”ì²œ
        reasoning_effort = self.recommend_reasoning_effort(complexity)
        verbosity = self.recommend_verbosity(prompt, complexity)

        # 5. XML êµ¬ì¡° í™•ì¸
        xml_structured = self.is_xml_structured(prompt)

        # 6. ì´ìŠˆ ë° ì œì•ˆ í†µí•©
        issues = []
        all_suggestions = []

        if contradictions:
            for contradiction in contradictions:
                issues.append({
                    'type': 'contradiction',
                    'severity': contradiction.severity,
                    'description': contradiction.description,
                    'fix': contradiction.fix_strategy
                })

        if agentic_score < 6:
            issues.append({
                'type': 'agentic_structure',
                'severity': 'medium',
                'description': f'Agentic êµ¬ì¡° ì ìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤ ({agentic_score:.1f}/10)',
                'fix': 'Agentic íŒ¨í„´ì„ ì¶”ê°€í•˜ì„¸ìš”'
            })

        if clarity_score < 6:
            issues.append({
                'type': 'clarity',
                'severity': 'medium',
                'description': f'ëª…í™•ì„± ì ìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤ ({clarity_score:.1f}/10)',
                'fix': 'XML êµ¬ì¡°ë‚˜ ëª…í™•í•œ ì„¹ì…˜ êµ¬ë¶„ì„ ì¶”ê°€í•˜ì„¸ìš”'
            })

        if context_score < 6:
            issues.append({
                'type': 'context_efficiency',
                'severity': 'low',
                'description': f'ì»¨í…ìŠ¤íŠ¸ íš¨ìœ¨ì„±ì´ ë‚®ìŠµë‹ˆë‹¤ ({context_score:.1f}/10)',
                'fix': 'ê· í˜•ì¡íŒ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ì§€ì‹œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”'
            })

        # ëª¨ë“  ì œì•ˆ í†µí•©
        all_suggestions.extend(agentic_suggestions)
        all_suggestions.extend(clarity_suggestions)
        all_suggestions.extend(context_suggestions)
        all_suggestions.extend(tool_suggestions)

        return GPT5AnalysisResult(
            original_prompt=prompt,
            contradictions=contradictions,
            agentic_score=agentic_score,
            clarity_score=clarity_score,
            context_efficiency_score=context_score,
            tool_preamble_quality=tool_preamble_score,
            reasoning_effort_recommendation=reasoning_effort.value,
            verbosity_recommendation=verbosity.value,
            xml_structured=xml_structured,
            issues=issues,
            suggestions=all_suggestions,
            complexity_score=complexity
        )


def format_analysis_result(result: GPT5AnalysisResult) -> str:
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…

    Args:
        result: GPT-5 ë¶„ì„ ê²°ê³¼

    Returns:
        í¬ë§·íŒ…ëœ ê²°ê³¼ ë¬¸ìì—´
    """
    output = []

    output.append("=" * 80)
    output.append("GPT-5 í”„ë¡¬í”„íŠ¸ ë¶„ì„ ê²°ê³¼")
    output.append("=" * 80)
    output.append("")

    # ì›ë³¸ í”„ë¡¬í”„íŠ¸
    output.append("ğŸ“ ì›ë³¸ í”„ë¡¬í”„íŠ¸:")
    output.append("-" * 80)
    output.append(result.original_prompt[:200] + "..." if len(result.original_prompt) > 200 else result.original_prompt)
    output.append("")

    # ì ìˆ˜
    output.append("ğŸ“Š ë¶„ì„ ì ìˆ˜:")
    output.append(f"  â€¢ Agentic êµ¬ì¡°: {result.agentic_score:.1f}/10")
    output.append(f"  â€¢ ëª…í™•ì„±: {result.clarity_score:.1f}/10")
    output.append(f"  â€¢ ì»¨í…ìŠ¤íŠ¸ íš¨ìœ¨ì„±: {result.context_efficiency_score:.1f}/10")
    output.append(f"  â€¢ ë„êµ¬ í”„ë¦¬ì•°ë¸” í’ˆì§ˆ: {result.tool_preamble_quality:.1f}/10")
    output.append(f"  â€¢ ë³µì¡ë„: {result.complexity_score:.1f}/10")
    output.append("")

    # íŒŒë¼ë¯¸í„° ì¶”ì²œ
    output.append("ğŸ¯ ì¶”ì²œ íŒŒë¼ë¯¸í„°:")
    output.append(f"  â€¢ reasoning_effort: {result.reasoning_effort_recommendation}")
    output.append(f"  â€¢ verbosity: {result.verbosity_recommendation}")
    output.append(f"  â€¢ XML êµ¬ì¡° ì‚¬ìš©: {'ì˜ˆ' if result.xml_structured else 'ì•„ë‹ˆì˜¤'}")
    output.append("")

    # ëª¨ìˆœ
    if result.contradictions:
        output.append("âš ï¸  ê°ì§€ëœ ëª¨ìˆœ:")
        for i, contradiction in enumerate(result.contradictions, 1):
            output.append(f"  {i}. {contradiction.description}")
            output.append(f"     ì‹¬ê°ë„: {contradiction.severity}")
            output.append(f"     ìˆ˜ì • ì „ëµ: {contradiction.fix_strategy}")
            output.append("")

    # ì´ìŠˆ
    if result.issues:
        output.append("ğŸ” ë°œê²¬ëœ ì´ìŠˆ:")
        for i, issue in enumerate(result.issues, 1):
            output.append(f"  {i}. [{issue['severity'].upper()}] {issue['description']}")
            output.append(f"     í•´ê²°ë°©ë²•: {issue['fix']}")
            output.append("")

    # ì œì•ˆ
    if result.suggestions:
        output.append("ğŸ’¡ ê°œì„  ì œì•ˆ:")
        for i, suggestion in enumerate(result.suggestions, 1):
            output.append(f"  {i}. {suggestion}")
        output.append("")

    output.append("=" * 80)

    return "\n".join(output)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    analyzer = GPT5PromptAnalyzer()

    test_prompt = """
    Never proceed without user confirmation but also auto-schedule appointments immediately.
    Maximize context gathering and read all possible files.
    """

    result = analyzer.analyze(test_prompt)
    print(format_analysis_result(result))
